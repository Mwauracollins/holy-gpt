{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1W7gXf1xnCA6_5UtPDZFbrJmoLQ95fQeS",
      "authorship_tag": "ABX9TyPjlmsiokC/9ShWijXepiki",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mwauracollins/holy-gpt/blob/main/src/bigram/nnModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBNb6zWi74f0",
        "outputId": "34157e15-b407-4a65-efdb-f1626633c140"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fpdhoW4CXKEV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "\n",
        "from tiktoken import get_encoding\n",
        "tokenizer = get_encoding(\"cl100k_base\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = \"drive/MyDrive/Datasets/recompiled.txt\""
      ],
      "metadata": {
        "id": "r25aOia6ekA9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = open(input_file, \"r\").read().splitlines()"
      ],
      "metadata": {
        "id": "zATt9Py9e0LR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [tokenizer.encode(word) for word in words]"
      ],
      "metadata": {
        "id": "Vg4i-EdR6e_2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = tokenizer.n_vocab"
      ],
      "metadata": {
        "id": "yW7LwcysgOP5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 3\n",
        "X, Y = [], []\n",
        "\n",
        "for token_list in tokens:\n",
        "    context = [0] * block_size\n",
        "    for token in token_list + [tokenizer.eot_token]:\n",
        "        X.append(context)\n",
        "        Y.append(token)\n",
        "        context = context[1:] + [token]\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "id": "dN4I459-i-Bg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape, X.dtype, Y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WVfJJp8t2k_",
        "outputId": "e3be2cd7-d8e0-42c8-9b08-e5f401631d89"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1058610, 3]), torch.Size([1058610]), torch.int64, torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 3\n",
        "\n",
        "def build_dataset(words):\n",
        "    X, Y = [], []\n",
        "    for token_list in tokens:\n",
        "        context = [0] * block_size\n",
        "        for token in token_list + [tokenizer.eot_token]:\n",
        "            X.append(context)\n",
        "            Y.append(token)\n",
        "            context = context[1:] + [token]\n",
        "\n",
        "    X = torch.tensor(X)\n",
        "    Y = torch.tensor(Y)\n",
        "    print(X.shape, Y.shape)\n",
        "    return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(tokens)\n",
        "n1 = int(0.8*len(tokens))\n",
        "n2 = int(0.9*len(tokens))\n",
        "\n",
        "Xtr, Ytr = build_dataset(tokens[:n1])\n",
        "Xdev, Ydev = build_dataset(tokens[n1:n2])\n",
        "Xte, Yte = build_dataset(tokens[n2:])\n",
        "print(Xtr.shape, Ytr.shape, Xdev.shape, Ydev.shape, Xte.shape, Yte.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaYJ2O8Nt5Br",
        "outputId": "03e1b135-dfe3-4597-92df-43d3d88100ff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1058610, 3]) torch.Size([1058610])\n",
            "torch.Size([1058610, 3]) torch.Size([1058610])\n",
            "torch.Size([1058610, 3]) torch.Size([1058610])\n",
            "torch.Size([1058610, 3]) torch.Size([1058610]) torch.Size([1058610, 3]) torch.Size([1058610]) torch.Size([1058610, 3]) torch.Size([1058610])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 10"
      ],
      "metadata": {
        "id": "21XNJZeyyy_K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(21)\n",
        "C = torch.randn((vocab_size, embedding_dim), generator=g)\n",
        "W1 = torch.randn((block_size * embedding_dim, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, vocab_size), generator=g)\n",
        "b2 = torch.randn(vocab_size, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "PjHNI_lH0FNO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clj-Bt6V0e3g",
        "outputId": "c9d8db04-3411-46a1-8ba9-b7a374e796b0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21164647"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "YuLyKhnf0ni8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lre = torch.linspace(-3, 0, 1000)\n",
        "lrs = 10**lre"
      ],
      "metadata": {
        "id": "-riCH3IE0uaJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lri = []\n",
        "lossi = []\n",
        "stepi = []"
      ],
      "metadata": {
        "id": "Yd6gvRDs0z3l"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(200000):\n",
        "    ix = torch.randint(0, Xtr.shape[0], (32,))\n",
        "\n",
        "    #forward pass\n",
        "    emb = C[Xtr[ix]]\n",
        "    h = torch.tanh(emb.view(-1, block_size * embedding_dim) @ W1 + b1)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = torch.nn.functional.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "    #backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    #update\n",
        "\n",
        "    lr = 0.1 if i < 100000 else 0.01\n",
        "    for p in parameters:\n",
        "        p.data += -lr * p.grad\n",
        "\n",
        "    stepi.append(i)\n",
        "    # lri.append(lr)\n",
        "    lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "id": "lfn6MTH705b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(stepi, lossi)"
      ],
      "metadata": {
        "id": "_LfGevrz1Ac4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# emb = C[Xtr]\n",
        "# h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
        "# logits = h @ W2 + b2\n",
        "# loss = torch.nn.functional.cross_entropy(logits, Ytr)\n",
        "# loss"
      ],
      "metadata": {
        "id": "gzw9oAMc11b-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# emb = C[Xdev]\n",
        "# h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
        "# logits = h @ W2 + b2\n",
        "# loss = torch.nn.functional.cross_entropy(logits, Ydev)\n",
        "# loss"
      ],
      "metadata": {
        "id": "rAPN4Gxu2iQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# context = [0] * block_size\n",
        "# C[torch.tensor(context)].shape"
      ],
      "metadata": {
        "id": "DDMGiIjN22r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,embedding_dim)\n",
        "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
        "      logits = h @ W2 + b2\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(tokenizer.decode(out))"
      ],
      "metadata": {
        "id": "Gd6uqEGG3a2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_to_str = {i: tokenizer.decode([i]) for i in range(vocab_size)}"
      ],
      "metadata": {
        "id": "YiXy_d9NASxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "plt.scatter(C[:200, 0].data, C[:200, 1].data, s=200)\n",
        "\n",
        "for i in range(200):\n",
        "    plt.text(C[i, 0].item(), C[i, 1].item(), int_to_str[i], ha=\"center\", va=\"center\", color='black')\n",
        "\n",
        "plt.grid('minor')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1xB_Act22q6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RT7UcSMM4YGE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}